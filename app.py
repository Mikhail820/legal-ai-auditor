import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import io
from PIL import Image

# --- 1. –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="LegalAI Enterprise Pro", page_icon="‚öñÔ∏è", layout="wide")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel('models/gemini-2.5-flash', generation_config={"temperature": 0.0}) 
else:
    st.error("üö® –î–æ–±–∞–≤—å—Ç–µ GOOGLE_API_KEY –≤ Secrets!")
    st.stop()

# --- 2. –§–£–ù–ö–¶–ò–ò ---

def extract_text(file):
    try:
        if file.name.endswith(".pdf"):
            return "".join([p.extract_text() for p in PdfReader(file).pages])
        elif file.name.endswith(".docx"):
            return "\n".join([p.text for p in Document(file).paragraphs])
        elif file.name.endswith(".txt"):
            raw = file.read()
            for enc in ['utf-8', 'windows-1251', 'cp1251']:
                try: return raw.decode(enc)
                except: continue
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"
    return ""

def create_docx_with_tables(report_text):
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Word —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏"""
    doc = Document()
    doc.add_heading('–Æ–†–ò–î–ò–ß–ï–°–ö–ò–ô –û–¢–ß–ï–¢', 0)
    
    lines = report_text.split('\n')
    table_data = []
    
    for line in lines:
        if '|' in line and '---' not in line:
            row = [cell.strip() for cell in line.split('|') if cell.strip()]
            if row: table_data.append(row)
        else:
            if table_data:
                table = doc.add_table(rows=0, cols=len(table_data[0]))
                table.style = 'Table Grid'
                for r in table_data:
                    row_cells = table.add_row().cells
                    for i, val in enumerate(r):
                        row_cells[i].text = val
                table_data = []
            if line.strip():
                doc.add_paragraph(line.strip())
    
    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf

# --- 3. –ò–ù–¢–ï–†–§–ï–ô–° –ò –ù–ê–°–¢–†–û–ô–ö–ò ---

with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í–´–ë–û–† –°–¢–ï–ü–ï–ù–ò –ê–ù–ê–õ–ò–ó–ê
    analysis_level = st.select_slider(
        "–ì–ª—É–±–∏–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:",
        options=["–ë–∞–∑–æ–≤–∞—è", "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è", "–ì–ª—É–±–æ–∫–∞—è"],
        value="–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è"
    )
    
    st.divider()
    
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –≤—Å—ë", use_container_width=True):
        st.session_state.clear()
        st.rerun()
        
    st.info(f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {analysis_level}")

st.title("‚öñÔ∏è LegalAI International System")

tab1, tab2 = st.tabs(["üöÄ –ê—É–¥–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞", "üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π"])

with tab1:
    col_in, col_out = st.columns([1, 1.2], gap="large")
    
    with col_in:
        st.subheader("–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö")
        mode = st.radio("–ò—Å—Ç–æ—á–Ω–∏–∫:", ["–§–∞–π–ª / –§–æ—Ç–æ", "–¢–µ–∫—Å—Ç"], horizontal=True)
        
        u_file = None
        txt_input = ""
        
        if mode == "–§–∞–π–ª / –§–æ—Ç–æ":
            u_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç", type=['pdf','docx','txt','jpg','png','jpeg'], key="file_audit")
        else:
            txt_input = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç:", height=300, key="text_audit")
            
        if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É", type="primary", use_container_width=True):
            content = ""
            is_img = False
            
            if u_file:
                if u_file.type in ['image/jpeg', 'image/png']:
                    content, is_img = Image.open(u_file), True
                else:
                    content = extract_text(u_file)
            else:
                content = txt_input
                
            if content:
                with st.spinner(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è {analysis_level} –∞–Ω–∞–ª–∏–∑..."):
                    prompts = {
                        "–ë–∞–∑–æ–≤–∞—è": "–ü—Ä–æ–≤–µ—Ä—å —Ç–æ–ª—å–∫–æ —à—Ç—Ä–∞—Ñ—ã –∏ —Å—Ä–æ–∫–∏ –æ–ø–ª–∞—Ç—ã.",
                        "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è": "–ü—Ä–æ–≤–µ—Ä—å —à—Ç—Ä–∞—Ñ—ã, —Å—Ä–æ–∫–∏, —É—Å–ª–æ–≤–∏—è —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏—è –∏ –ø–æ–¥—Å—É–¥–Ω–æ—Å—Ç—å.",
                        "–ì–ª—É–±–æ–∫–∞—è": "–ü–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç: —Ä–∏—Å–∫–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, —Å–∫—Ä—ã—Ç—ã–µ –∫–æ–º–∏—Å—Å–∏–∏, –±–∞–ª–∞–Ω—Å –ø—Ä–∞–≤ —Å—Ç–æ—Ä–æ–Ω –∏ –≤—Å–µ –ª–∞–∑–µ–π–∫–∏."
                    }
                    
                    sys_msg = f"""
                    –¢–´ ‚Äî –≠–ö–°–ü–ï–†–¢-–Æ–†–ò–°–¢. –ì–õ–£–ë–ò–ù–ê: {analysis_level}. {prompts[analysis_level]}
                    –û–¢–ß–ï–¢ –°–¢–†–û–ì–û –ü–û –§–û–†–ú–ê–¢–£:
                    1. JURISDICTION: [–°—Ç—Ä–∞–Ω–∞]
                    2. VERDICT: [üü¢/üü°/üî¥]
                    3. –¢–ê–ë–õ–ò–¶–ê –†–ò–°–ö–û–í:
                    | –ü–£–ù–ö–¢ | –†–ò–°–ö | –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø |
                    |---|---|---|
                    [–ó–∞–ø–æ–ª–Ω–∏ —Ç–∞–±–ª–∏—Ü—É]
                    
                    –ë–ï–ó –í–í–û–î–ù–´–• –°–õ–û–í.
                    """
                    
                    try:
                        res = model.generate_content([sys_msg, content]) if is_img else model.generate_content(f"{sys_msg}\n\n{content[:20000]}")
                        st.session_state['main_report'] = res.text
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ò–ò: {e}")

    with col_out:
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç")
        if 'main_report' in st.session_state:
            report = st.session_state['main_report']
            st.markdown(report)
            
            word_file = create_docx_with_tables(report)
            st.download_button("üì• –°–∫–∞—á–∞—Ç—å Word", data=word_file, file_name="Legal_Audit.docx", use_container_width=True)

with tab2:
    st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–¥–∞–∫—Ü–∏–π")
    c1, c2 = st.columns(2)
    with c1: f1 = st.file_uploader("–û—Ä–∏–≥–∏–Ω–∞–ª", key="comp1")
    with c2: f2 = st.file_uploader("–ü—Ä–∞–≤–∫–∏", key="comp2")
    
    if st.button("üîé –°—Ä–∞–≤–Ω–∏—Ç—å", use_container_width=True):
        if f1 and f2:
            with st.spinner("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ..."):
                t1, t2 = extract_text(f1), extract_text(f2)
                diff_res = model.generate_content(f"–°—Ä–∞–≤–Ω–∏ —Ç–µ–∫—Å—Ç—ã –∏ –≤—ã–¥–µ–ª–∏ —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è, —É—Ö—É–¥—à–∞—é—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –ó–∞–∫–∞–∑—á–∏–∫–∞:\n1: {t1[:9000]}\n2: {t2[:9000]}")
                st.markdown(diff_res.text)
            
