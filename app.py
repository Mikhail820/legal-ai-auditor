import streamlit as st
import requests
import re
import base64
from PyPDF2 import PdfReader
from docx import Document
from bs4 import BeautifulSoup

# --- 1. –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="LegalAI Analyzer", layout="wide", page_icon="üõ°Ô∏è")

def anonymize_text(text):
    """–°–∫—Ä—ã–≤–∞–µ—Ç –ø–∞—Å–ø–æ—Ä—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç–µ–ª–µ—Ñ–æ–Ω—ã"""
    patterns = {
        r'\b\d{4}\s\d{6}\b': '[–ü–ê–°–ü–û–†–¢]',
        r'\b\+?\d{1,3}[-.\s]?\(?\d{1,4}?\)?[-.\s]?\d{1,4}[-.\s]?\d{1,4}\b': '[–¢–ï–õ–ï–§–û–ù]',
    }
    for pattern, replacement in patterns.items():
        text = re.sub(pattern, replacement, text)
    return text

# --- 2. API LOGIC (–ü–†–Ø–ú–û–ô –í–´–ó–û–í) ---
def call_gemini(prompt, content, is_img=False):
    # –ë–µ—Ä–µ–º –∫–ª—é—á –Ω–∞–ø—Ä—è–º—É—é –∏–∑ Secrets
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        return "‚ùå –û—à–∏–±–∫–∞: –ö–ª—é—á 'GOOGLE_API_KEY' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö (Secrets)."

    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={api_key}"
    
    if not is_img:
        content = anonymize_text(content)
    
    parts = [{"text": f"{prompt}\n\nCONTENT:\n{content}"}]
    if is_img:
        parts = [{"text": prompt}, {"inline_data": {"mime_type": "image/jpeg", "data": base64.b64encode(content).decode()}}]
    
    payload = {
        "contents": [{"parts": parts}],
        "generationConfig": {"temperature": 0.1, "maxOutputTokens": 2000}
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        res_json = response.json()
        if "candidates" in res_json:
            return res_json['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API: {res_json.get('error', {}).get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–≤—è–∑–∏: {str(e)}"

# --- 3. –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¢–ï–ö–°–¢–ê ---
def extract_from_file(file):
    try:
        if file.name.endswith(".pdf"):
            return " ".join([p.extract_text() for p in PdfReader(file).pages])
        elif file.name.endswith(".docx"):
            return "\n".join([p.text for p in Document(file).paragraphs])
    except:
        return "–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞."
    return ""

def extract_from_url(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        for s in soup(["script", "style"]): s.decompose()
        return soup.get_text(separator=' ')[:20000]
    except:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ —Å—Å—ã–ª–∫–µ."

# --- 4. –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title("‚öñÔ∏è LegalAI: –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –ê—É–¥–∏—Ç")

with st.sidebar:
    audience = st.radio("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫:", ["–ì—Ä–∞–∂–¥–∞–Ω–∏–Ω", "–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å", "–Æ—Ä–∏—Å—Ç"])
    st.divider()
    st.write("üõ°Ô∏è –î–∞–Ω–Ω—ã–µ –æ–±–µ–∑–ª–∏—á–∏–≤–∞—é—Ç—Å—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.")

tab1, tab2 = st.tabs(["üìÑ –§–∞–π–ª / –§–æ—Ç–æ", "üîó –°—Å—ã–ª–∫–∞"])

with tab1:
    up = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–≥–æ–≤–æ—Ä", type=["pdf", "docx", "jpg", "png"])

with tab2:
    url_input = st.text_input("–°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ñ–µ—Ä—Ç—É")

if st.button("üöÄ –ù–ê–ß–ê–¢–¨ –ê–£–î–ò–¢", type="primary"):
    txt_to_analyze = ""
    is_image = False
    
    if up:
        if up.type.startswith("image"):
            txt_to_analyze = up.getvalue()
            is_image = True
        else:
            txt_to_analyze = extract_from_file(up)
    elif url_input:
        txt_to_analyze = extract_from_url(url_input)

    if txt_to_analyze:
        with st.spinner("–ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç..."):
            prompts = {
                "–ì—Ä–∞–∂–¥–∞–Ω–∏–Ω": "–ù–∞–π–¥–∏ –ª–æ–≤—É—à–∫–∏ –∏ –æ–±—ä—è—Å–Ω–∏ –∏—Ö –ø—Ä–æ—Å—Ç–æ. –°–¥–µ–ª–∞–π SCORE: X/100.",
                "–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å": "–û—Ü–µ–Ω–∏ —à—Ç—Ä–∞—Ñ—ã –∏ —Ä–∏—Å–∫–∏ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞. –°–¥–µ–ª–∞–π SCORE: X/100.",
                "–Æ—Ä–∏—Å—Ç": "–ù–∞–π–¥–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∑–∞–∫–æ–Ω–∞–º –†–§. –°–¥–µ–ª–∞–π SCORE: X/100."
            }
            main_p = f"Role: Senior Lawyer. Audience: {audience}. {prompts[audience]} Format: SCORE, üî¥ –†–ò–°–ö–ò, üü° –°–û–í–ï–¢–´, üü¢ –ß–ï–ö-–õ–ò–°–¢."
            
            result = call_gemini(main_p, txt_to_analyze, is_img=is_image)
            st.session_state.res = result
            st.markdown(result)
    else:
        st.error("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É.")
    
